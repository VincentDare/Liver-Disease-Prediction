{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc074bf4",
   "metadata": {},
   "source": [
    "PROJECT JARINGAN SYARAF TIRUAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c47b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    object \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  579 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Membaca Data\n",
    "df = pd.read_csv(\"C:/Users/USER/Documents/Python/Jaringan Syaraf Tiruan Project/indian_liver_patient.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5971b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                           0\n",
      "Gender                        0\n",
      "Total_Bilirubin               0\n",
      "Direct_Bilirubin              0\n",
      "Alkaline_Phosphotase          0\n",
      "Alamine_Aminotransferase      0\n",
      "Aspartate_Aminotransferase    0\n",
      "Total_Protiens                0\n",
      "Albumin                       0\n",
      "Albumin_and_Globulin_Ratio    4\n",
      "Dataset                       0\n",
      "dtype: int64\n",
      "count    579.000000\n",
      "mean       0.947064\n",
      "std        0.319592\n",
      "min        0.300000\n",
      "25%        0.700000\n",
      "50%        0.930000\n",
      "75%        1.100000\n",
      "max        2.800000\n",
      "Name: Albumin_and_Globulin_Ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df['Albumin_and_Globulin_Ratio'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55314f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    object \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  583 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3088\\2480636606.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Albumin_and_Globulin_Ratio'].fillna(df['Albumin_and_Globulin_Ratio'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Mengisi missing values dengan median\n",
    "df['Albumin_and_Globulin_Ratio'].fillna(df['Albumin_and_Globulin_Ratio'].median(), inplace=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e465b",
   "metadata": {},
   "source": [
    "SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47965b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((466, 10), (117, 10), (466,), (117,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode gender: Male=1, Female=0\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Dataset']).values\n",
    "y = df['Dataset'].values\n",
    "y = (y == 2).astype(int)  # 0 = Liver disease, 1 = No liver disease\n",
    "\n",
    "# Custom train-test split function\n",
    "def tt_split(X, y, test_size=0.2): \n",
    "    i = int((1 - test_size) * X.shape[0]) \n",
    "    o = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    X_train, X_test = np.split(np.take(X, o, axis=0), [i])\n",
    "    y_train, y_test = np.split(np.take(y, o), [i])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Perform the split\n",
    "X_train, X_test, y_train, y_test = tt_split(X, y, test_size=0.2)\n",
    "\n",
    "# Output the shapes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446c826",
   "metadata": {},
   "source": [
    "MODEL BACKPROPAGATION\n",
    "\n",
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07aea754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "        self.weights_input_hidden = np.random.randn(self.input_layer, self.hidden_layer)\n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_layer, self.output_layer)\n",
    "\n",
    "        self.bias_hidden = np.zeros((1, self.hidden_layer))\n",
    "        self.bias_output = np.zeros((1, self.output_layer))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_layer = self.sigmoid(self.hidden_activation)\n",
    "\n",
    "        self.output_activation = np.dot(self.hidden_layer, self.weights_hidden_output) + self.bias_output\n",
    "        self.predicted_output = self.sigmoid(self.output_activation)\n",
    "\n",
    "        return self.predicted_output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "    # 1. Hitung error output dan delta\n",
    "        output_error = y - self.predicted_output  # bentuk: (n_samples, output_size)\n",
    "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)\n",
    "\n",
    "    # 2. Hitung error hidden dan delta\n",
    "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_layer)\n",
    "\n",
    "    # 3. Update bobot dan bias\n",
    "        self.weights_hidden_output += np.dot(self.hidden_layer.T, output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.feedforward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "            if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "                loss = np.mean((y - self.predicted_output) ** 2)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.feedforward(X)\n",
    "        return (output > 0.5).astype(int)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc3974",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b5a8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3088\\3780582752.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2737\n",
      "Epoch 1000, Loss: 0.2076\n",
      "Epoch 2000, Loss: 0.2076\n",
      "Epoch 3000, Loss: 0.2076\n",
      "Epoch 4000, Loss: 0.2076\n",
      "Epoch 5000, Loss: 0.2076\n",
      "Epoch 6000, Loss: 0.2076\n",
      "Epoch 7000, Loss: 0.2076\n",
      "Epoch 8000, Loss: 0.2076\n",
      "Epoch 9000, Loss: 0.2076\n",
      "Epoch 10000, Loss: 0.2076\n",
      "Epoch 11000, Loss: 0.2076\n",
      "Epoch 12000, Loss: 0.2076\n",
      "Epoch 13000, Loss: 0.2076\n",
      "Epoch 14000, Loss: 0.2076\n",
      "Epoch 15000, Loss: 0.2076\n",
      "Epoch 16000, Loss: 0.2076\n",
      "Epoch 17000, Loss: 0.2076\n",
      "Epoch 18000, Loss: 0.2076\n",
      "Epoch 19000, Loss: 0.2076\n",
      "Epoch 19999, Loss: 0.2076\n",
      "Akurasi: 74.36%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshape y_train and y_test to be 2D arrays\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "nn = NeuralNetwork(input_layer=10, hidden_layer=2, output_layer=1)\n",
    "nn.train(X_train, y_train, epochs=20000, learning_rate=0.01)\n",
    "\n",
    "# Evaluasi\n",
    "predictions = nn.predict(X_test)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Akurasi: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e12ef",
   "metadata": {},
   "source": [
    "TEST DATA BARU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9edf1915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasien 1: tidak menderita liver\n",
      "Pasien 2: tidak menderita liver\n",
      "Pasien 3: menderita liver\n",
      "Pasien 4: tidak menderita liver\n",
      "Pasien 5: menderita liver\n"
     ]
    }
   ],
   "source": [
    "# Membuat data pasien baru\n",
    "pasien_baru = np.array([\n",
    "    [65, 1, 3.5, 2.0, 300, 80, 90, 5.0, 2.0, 0.5],   \n",
    "    [58, 1, 2.8, 1.5, 250, 70, 85, 5.5, 2.3, 0.7],   \n",
    "    [75, 0, 9.0, 5.0, 650, 210, 260, 3.8, 0.9, 0.2],   \n",
    "    [80, 1, 10.0, 6.0, 700, 220, 270, 3.5, 0.8, 0.1],   \n",
    "    [70, 1, 4.0, 2.5, 320, 90, 100, 4.8, 8.8, 1.6]       \n",
    "])\n",
    "# Normalisasi data pasien baru\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "pasien_baru_scaled = (pasien_baru - mean) / std\n",
    "prediksi = nn.predict(pasien_baru_scaled)\n",
    "# Output prediksi\n",
    "for i, hasil in enumerate(prediksi):\n",
    "    status = \"menderita liver\" if hasil[0] == 1 else \"tidak menderita liver\"\n",
    "    print(f\"Pasien {i+1}: {status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
